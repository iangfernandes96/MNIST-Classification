{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(2018)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Image rows: 28\n",
      "Image columns: 28\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()\n",
    "_, img_rows, img_cols =  train_features.shape\n",
    "num_classes = len(np.unique(train_labels))\n",
    "num_input_nodes = img_rows*img_cols\n",
    "print (\"Number of training samples:\",train_features.shape[0])\n",
    "print (\"Number of test samples:\",test_features.shape[0])\n",
    "print (\"Image rows:\",train_features.shape[1])\n",
    "print (\"Image columns:\",train_features.shape[2])\n",
    "print (\"Number of classes:\",num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Examples from Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAADECAYAAAAvbXA5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4jdSVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d59087eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    features_idx = train_features[train_labels[:]==i,:]\n",
    "    ax.set_title(\"Num: \" + str(i))\n",
    "    plt.imshow(features_idx[1], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape images to column vectors\n",
    "train_features = train_features.reshape(train_features.shape[0], img_rows*img_cols)\n",
    "test_features = test_features.reshape(test_features.shape[0], img_rows*img_cols)\n",
    "# convert class labels to binary class labels\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider batch_size=100 and epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model: \n",
    "- 1 hidden layer with 512 nodes \n",
    "- Hidden layer uses tanh activation\n",
    "- Output layer uses sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and hidden layer\n",
    "model.add(Dense(512, activation='tanh', input_dim = num_input_nodes))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.6371 - acc: 0.8182 - val_loss: 0.3503 - val_acc: 0.9080\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.3188 - acc: 0.9125 - val_loss: 0.2678 - val_acc: 0.9264\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.2655 - acc: 0.9254 - val_loss: 0.2411 - val_acc: 0.9319\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.2396 - acc: 0.9330 - val_loss: 0.2288 - val_acc: 0.9351\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.2161 - acc: 0.9389 - val_loss: 0.2127 - val_acc: 0.9390\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.2010 - acc: 0.9433 - val_loss: 0.1948 - val_acc: 0.9437\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1853 - acc: 0.9473 - val_loss: 0.1815 - val_acc: 0.9485\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1784 - acc: 0.9492 - val_loss: 0.1777 - val_acc: 0.9487\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1681 - acc: 0.9522 - val_loss: 0.1756 - val_acc: 0.9480\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.1613 - acc: 0.9537 - val_loss: 0.1655 - val_acc: 0.9513\n",
      "Test loss: 0.165545813996\n",
      "Test accuracy: 0.9513\n"
     ]
    }
   ],
   "source": [
    "model_info = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model:\n",
    "- 2 hidden layer with 512 nodes with tanh activation\n",
    "- Output layer uses sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='tanh', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 9s - loss: 0.6965 - acc: 0.8236 - val_loss: 0.3540 - val_acc: 0.9086\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.3161 - acc: 0.9144 - val_loss: 0.2791 - val_acc: 0.9255\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.2590 - acc: 0.9280 - val_loss: 0.2379 - val_acc: 0.9336\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.2285 - acc: 0.9360 - val_loss: 0.2163 - val_acc: 0.9390\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.2079 - acc: 0.9404 - val_loss: 0.2066 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1988 - acc: 0.9437 - val_loss: 0.1942 - val_acc: 0.9441\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1830 - acc: 0.9480 - val_loss: 0.1824 - val_acc: 0.9481\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1727 - acc: 0.9505 - val_loss: 0.1740 - val_acc: 0.9479\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1669 - acc: 0.9530 - val_loss: 0.1705 - val_acc: 0.9497\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1584 - acc: 0.9542 - val_loss: 0.1659 - val_acc: 0.9511\n",
      "Test loss: 0.165906652528\n",
      "Test accuracy: 0.9511\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Model:\n",
    "- 1 hidden layer with 512 nodes with sigmoid activation\n",
    "- Output layer uses softmax activation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and hidden layer\n",
    "model.add(Dense(512, activation='sigmoid', input_dim = num_input_nodes))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.6506 - acc: 0.8337 - val_loss: 0.3719 - val_acc: 0.9040\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.3319 - acc: 0.9114 - val_loss: 0.2945 - val_acc: 0.9208\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.2728 - acc: 0.9256 - val_loss: 0.2558 - val_acc: 0.9305\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.2383 - acc: 0.9350 - val_loss: 0.2304 - val_acc: 0.9361\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.2132 - acc: 0.9417 - val_loss: 0.2137 - val_acc: 0.9415\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.1944 - acc: 0.9473 - val_loss: 0.2004 - val_acc: 0.9430\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.1788 - acc: 0.9515 - val_loss: 0.1890 - val_acc: 0.9458\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.1674 - acc: 0.9555 - val_loss: 0.1823 - val_acc: 0.9467\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.1558 - acc: 0.9583 - val_loss: 0.1759 - val_acc: 0.9502\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.1465 - acc: 0.9616 - val_loss: 0.1675 - val_acc: 0.9512\n",
      "Test loss: 0.167488641082\n",
      "Test accuracy: 0.9512\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Model:\n",
    "- 2 hidden layer with 512 nodes with sigmoid activation\n",
    "- Output layer uses softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='sigmoid', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s - loss: 1.4236 - acc: 0.7154 - val_loss: 0.8506 - val_acc: 0.8388\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.6622 - acc: 0.8645 - val_loss: 0.5177 - val_acc: 0.8835\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.4607 - acc: 0.8914 - val_loss: 0.3995 - val_acc: 0.9015\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.3759 - acc: 0.9063 - val_loss: 0.3430 - val_acc: 0.9136\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.3271 - acc: 0.9144 - val_loss: 0.3088 - val_acc: 0.9180\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2950 - acc: 0.9211 - val_loss: 0.2850 - val_acc: 0.9221\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2708 - acc: 0.9270 - val_loss: 0.2671 - val_acc: 0.9280\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2518 - acc: 0.9312 - val_loss: 0.2518 - val_acc: 0.9307\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2361 - acc: 0.9349 - val_loss: 0.2401 - val_acc: 0.9334\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2225 - acc: 0.9390 - val_loss: 0.2302 - val_acc: 0.9356\n",
      "Test loss: 0.230201293856\n",
      "Test accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Model:\n",
    "- 1 hidden layer with 512 nodes with sigmoid activation\n",
    "- Output layer uses sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='sigmoid', input_dim = num_input_nodes))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.8293 - acc: 0.7925 - val_loss: 0.4053 - val_acc: 0.9039\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.3609 - acc: 0.9071 - val_loss: 0.3084 - val_acc: 0.9229\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.2883 - acc: 0.9232 - val_loss: 0.2631 - val_acc: 0.9315\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.2488 - acc: 0.9336 - val_loss: 0.2361 - val_acc: 0.9369\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.2225 - acc: 0.9398 - val_loss: 0.2160 - val_acc: 0.9420\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.2018 - acc: 0.9454 - val_loss: 0.1998 - val_acc: 0.9446\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.1854 - acc: 0.9499 - val_loss: 0.1902 - val_acc: 0.9475\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.1723 - acc: 0.9531 - val_loss: 0.1827 - val_acc: 0.9480\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s - loss: 0.1616 - acc: 0.9566 - val_loss: 0.1754 - val_acc: 0.9496\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 11s - loss: 0.1508 - acc: 0.9603 - val_loss: 0.1701 - val_acc: 0.9513\n",
      "Test loss: 0.170108123621\n",
      "Test accuracy: 0.9513\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sixth Model:\n",
    "- 2 hidden layer with 512 nodes with sigmoid activation\n",
    "- Output layer uses sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='sigmoid', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s - loss: 1.7430 - acc: 0.6150 - val_loss: 1.0830 - val_acc: 0.8173\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s - loss: 0.8011 - acc: 0.8472 - val_loss: 0.5951 - val_acc: 0.8807\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.5170 - acc: 0.8863 - val_loss: 0.4362 - val_acc: 0.8999\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.4046 - acc: 0.9022 - val_loss: 0.3631 - val_acc: 0.9102\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 19s - loss: 0.3443 - acc: 0.9130 - val_loss: 0.3200 - val_acc: 0.9166\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s - loss: 0.3063 - acc: 0.9197 - val_loss: 0.2939 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2793 - acc: 0.9251 - val_loss: 0.2720 - val_acc: 0.9276\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2582 - acc: 0.9305 - val_loss: 0.2563 - val_acc: 0.9305\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s - loss: 0.2413 - acc: 0.9343 - val_loss: 0.2426 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s - loss: 0.2257 - acc: 0.9384 - val_loss: 0.2311 - val_acc: 0.9359\n",
      "Test loss: 0.231146301287\n",
      "Test accuracy: 0.9359\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best model: 2 hidden layers with tanh and output layer with sigmoid activation and increasing the number of epochs to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='tanh', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.6769 - acc: 0.8261 - val_loss: 0.3501 - val_acc: 0.9089\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3107 - acc: 0.9166 - val_loss: 0.2735 - val_acc: 0.9253\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2552 - acc: 0.9297 - val_loss: 0.2375 - val_acc: 0.9344\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2251 - acc: 0.9381 - val_loss: 0.2133 - val_acc: 0.9397\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2059 - acc: 0.9423 - val_loss: 0.2035 - val_acc: 0.9411\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1905 - acc: 0.9468 - val_loss: 0.1862 - val_acc: 0.9466\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1762 - acc: 0.9500 - val_loss: 0.1822 - val_acc: 0.9455\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1683 - acc: 0.9524 - val_loss: 0.1753 - val_acc: 0.9506\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1622 - acc: 0.9528 - val_loss: 0.1658 - val_acc: 0.9517\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1540 - acc: 0.9561 - val_loss: 0.1597 - val_acc: 0.9507\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1508 - acc: 0.9564 - val_loss: 0.1604 - val_acc: 0.9525\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1443 - acc: 0.9578 - val_loss: 0.1587 - val_acc: 0.9522\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1414 - acc: 0.9595 - val_loss: 0.1503 - val_acc: 0.9554\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1344 - acc: 0.9612 - val_loss: 0.1402 - val_acc: 0.9602\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1267 - acc: 0.9630 - val_loss: 0.1435 - val_acc: 0.9554\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1271 - acc: 0.9624 - val_loss: 0.1364 - val_acc: 0.9593\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1230 - acc: 0.9641 - val_loss: 0.1428 - val_acc: 0.9572\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1223 - acc: 0.9640 - val_loss: 0.1374 - val_acc: 0.9581\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1174 - acc: 0.9655 - val_loss: 0.1353 - val_acc: 0.9604\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.1179 - acc: 0.9656 - val_loss: 0.1371 - val_acc: 0.9568\n",
      "Test loss: 0.137073442586\n",
      "Test accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "Increasing the number of epochs gave us better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='tanh', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.9059 - acc: 0.7670 - val_loss: 0.4429 - val_acc: 0.8928\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.3878 - acc: 0.8983 - val_loss: 0.3293 - val_acc: 0.9161\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.3083 - acc: 0.9167 - val_loss: 0.2780 - val_acc: 0.9272\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2659 - acc: 0.9276 - val_loss: 0.2545 - val_acc: 0.9314\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2392 - acc: 0.9338 - val_loss: 0.2293 - val_acc: 0.9345\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.2147 - acc: 0.9397 - val_loss: 0.2142 - val_acc: 0.9392\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2008 - acc: 0.9437 - val_loss: 0.2046 - val_acc: 0.9412\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1870 - acc: 0.9469 - val_loss: 0.1938 - val_acc: 0.9454\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1751 - acc: 0.9508 - val_loss: 0.1867 - val_acc: 0.9462\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1670 - acc: 0.9524 - val_loss: 0.1759 - val_acc: 0.9471\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.1541 - acc: 0.9568 - val_loss: 0.1720 - val_acc: 0.9491 1s - loss: 0.\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1467 - acc: 0.9586 - val_loss: 0.1654 - val_acc: 0.9515\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.1394 - acc: 0.9621 - val_loss: 0.1584 - val_acc: 0.9528\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1330 - acc: 0.9631 - val_loss: 0.1559 - val_acc: 0.9541\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1279 - acc: 0.9643 - val_loss: 0.1539 - val_acc: 0.9566\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.1224 - acc: 0.9663 - val_loss: 0.1528 - val_acc: 0.9533\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.1171 - acc: 0.9675 - val_loss: 0.1490 - val_acc: 0.9564\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.1114 - acc: 0.9694 - val_loss: 0.1418 - val_acc: 0.9556\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1067 - acc: 0.9707 - val_loss: 0.1382 - val_acc: 0.9576\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.1034 - acc: 0.9715 - val_loss: 0.1384 - val_acc: 0.9581\n",
      "Test loss: 0.138448170105\n",
      "Test accuracy: 0.9581\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "Increasing batch size increased accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using optimiser sgd with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='tanh', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Print model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and sgd optimiser with momentum\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.5374 - acc: 0.8511 - val_loss: 0.4042 - val_acc: 0.8830\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.4036 - acc: 0.8795 - val_loss: 0.4159 - val_acc: 0.8752\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.4200 - acc: 0.8707 - val_loss: 0.4208 - val_acc: 0.8678\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 7s - loss: 0.4312 - acc: 0.8627 - val_loss: 0.3850 - val_acc: 0.8849\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3901 - acc: 0.8775 - val_loss: 0.3676 - val_acc: 0.8883\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3726 - acc: 0.8831 - val_loss: 0.3325 - val_acc: 0.8986\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3585 - acc: 0.8864 - val_loss: 0.4049 - val_acc: 0.8661\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3588 - acc: 0.8875 - val_loss: 0.3190 - val_acc: 0.8993\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3328 - acc: 0.8945 - val_loss: 0.3302 - val_acc: 0.8949\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.3114 - acc: 0.9023 - val_loss: 0.3006 - val_acc: 0.9063\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2984 - acc: 0.9073 - val_loss: 0.2837 - val_acc: 0.9107\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2906 - acc: 0.9076 - val_loss: 0.2888 - val_acc: 0.9128\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2786 - acc: 0.9138 - val_loss: 0.2635 - val_acc: 0.9172\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2657 - acc: 0.9174 - val_loss: 0.2521 - val_acc: 0.9213\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2698 - acc: 0.9150 - val_loss: 0.2822 - val_acc: 0.9123\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2889 - acc: 0.9092 - val_loss: 0.3035 - val_acc: 0.9042\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2793 - acc: 0.9117 - val_loss: 0.2474 - val_acc: 0.9210\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 8s - loss: 0.2463 - acc: 0.9223 - val_loss: 0.2385 - val_acc: 0.9253\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2437 - acc: 0.9247 - val_loss: 0.2381 - val_acc: 0.9244\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2350 - acc: 0.9267 - val_loss: 0.2346 - val_acc: 0.9255\n",
      "Test loss: 0.234642665607\n",
      "Test accuracy: 0.9255\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using optimiser: Adagrad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise model\n",
    "model = Sequential()\n",
    "#Add input and 1st hidden layer\n",
    "model.add(Dense(512, activation='tanh', input_dim = num_input_nodes))\n",
    "#Add 2nd hidden layer\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "#Add output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling model: Using categorical crossentropy loss function and adagrad optimiser\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.5208 - acc: 0.8313 - val_loss: 0.2306 - val_acc: 0.9319\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 9s - loss: 0.2194 - acc: 0.9329 - val_loss: 0.1994 - val_acc: 0.9365\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.1766 - acc: 0.9468 - val_loss: 0.1692 - val_acc: 0.9477\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.1498 - acc: 0.9547 - val_loss: 0.1489 - val_acc: 0.9524\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.1347 - acc: 0.9593 - val_loss: 0.1447 - val_acc: 0.9553\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.1224 - acc: 0.9634 - val_loss: 0.1366 - val_acc: 0.9580\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.1127 - acc: 0.9655 - val_loss: 0.1241 - val_acc: 0.9624\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.1037 - acc: 0.9684 - val_loss: 0.1245 - val_acc: 0.9642\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0974 - acc: 0.9700 - val_loss: 0.1170 - val_acc: 0.9635\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0901 - acc: 0.9727 - val_loss: 0.1164 - val_acc: 0.9634\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0842 - acc: 0.9741 - val_loss: 0.1067 - val_acc: 0.9657\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0774 - acc: 0.9763 - val_loss: 0.1030 - val_acc: 0.9668\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0720 - acc: 0.9784 - val_loss: 0.1050 - val_acc: 0.9681\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 11s - loss: 0.0679 - acc: 0.9798 - val_loss: 0.1039 - val_acc: 0.9672\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0646 - acc: 0.9813 - val_loss: 0.0971 - val_acc: 0.9701\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0610 - acc: 0.9816 - val_loss: 0.0954 - val_acc: 0.9689\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0590 - acc: 0.9822 - val_loss: 0.0939 - val_acc: 0.9694\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0565 - acc: 0.9835 - val_loss: 0.0949 - val_acc: 0.9676\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0539 - acc: 0.9841 - val_loss: 0.0977 - val_acc: 0.9696\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 10s - loss: 0.0511 - acc: 0.9851 - val_loss: 0.0937 - val_acc: 0.9711\n",
      "Test loss: 0.0937156034093\n",
      "Test accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_features, test_labels))\n",
    "#Evaluating model\n",
    "score = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "Adagrad optimiser gives us the best accuracy of 97.11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting loss and accuracy of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to plot loss and accuracy\n",
    "def plot_model(model_info):\n",
    "    fig, axis = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    # summarize history for loss\n",
    "    axis[1].plot(range(1,len(model_info.history['loss'])+1),model_info.history['loss'])\n",
    "    axis[1].plot(range(1,len(model_info.history['val_loss'])+1),model_info.history['val_loss'])\n",
    "    axis[1].set_title('Model Loss')\n",
    "    axis[1].set_ylabel('Loss')\n",
    "    axis[1].set_xlabel('Epoch')\n",
    "    axis[1].set_xticks(np.arange(1,len(model_info.history['loss'])+1),len(model_info.history['loss'])/10)\n",
    "    axis[1].legend(['train', 'val'], loc='best')\n",
    "    axis[0].plot(range(1,len(model_info.history['acc'])+1),model_info.history['acc'])\n",
    "    axis[0].plot(range(1,len(model_info.history['val_acc'])+1),model_info.history['val_acc'])\n",
    "    axis[0].set_title('Model Accuracy')\n",
    "    axis[0].set_ylabel('Accuracy')\n",
    "    axis[0].set_xlabel('Epoch')\n",
    "    axis[0].set_xticks(np.arange(1,len(model_info.history['acc'])+1),len(model_info.history['acc'])/10)\n",
    "    axis[0].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAFNCAYAAABVKNEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkRFGiaCIiIiIiMgIo0RQRERERERkhPn/gbRNi50K2wIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d3fdb4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "The best result was obtained from the model with\n",
    "2 hidden layers of 512 nodes each with 'tanh' activation and an output layer with 'sigmoid' activation\n",
    "The Adagrad optimiser gave us the best result with an accuracy of 97.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
